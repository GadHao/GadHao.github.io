---
layout: post
title: '深入理解计算机系统 - 信息的表示和处理'
date: 2020-09-15
author: HANABI
color: rgb(54,59,64)
tags: 地基系列 计算机系统
---

> 在这一章，我们会了解表示基本数据类型的方法，机器级指令如何操作这样的数据，编译器如何将C程序翻译成这样的指令。接着会研究几种实现处理器的方法，帮助我们更好地了解硬件资源如何被用来执行命令。在深入了解了如何表示和执行应用程序之后，我们将学会一些技巧，用来写出安全、可靠且充分利用计算机资源的程序

## 信息的表示和处理

现代计算机存储和处理的信息以二值信号表示。这些二进制数字，或者称为位(bit)，形成了数字革命的基础。以前，大家熟悉并使用了1000多年的十进制数字起源于印度，在12世纪被阿拉伯数学家改进，并在13世纪被意大利数学家Leonardo Pisano(更为大家熟知的名字是Fibonacci)带到西方。

对于有10个手指的人类，使用十进制表示法是很自然的事情，但是当构造存储和处理信息的机器时，二进制值工作得更好。其可以更容易地被表示、存储和传输，里如可以表示为卡片上有没有孔洞、导线上的高电压或低电压，或者顺时针或逆时针的磁场。对二值信号进行存储和执行计算的电子电路非常简单可靠，制造商能够在一个单独的硅片上集成数百万甚至数十亿个这样的电路。

单个的位不是很有用，然而当把位组合在一起，再加上某种解释(interpretation)，就可以赋予它们含义，并用来表示任何有限集合的元素。比如，使用一个二进制数字系统，我们能够用位组来编码非负数。通过标准的字符码，我们能够对文档中的字母和符号进行编码。

我们研究三种最重要的数字表示：

1. **无符号(unsigned)**编码：表示大于或等于0的数字
2. **补码(two's-complement)**编码：表示有符号整数
3. **浮点数(floating-point)**编码：表示实数的科学计数法的以2为基数的版本

计算机的表示法是用有限数量的位来对一个数字编码，所以如果结果太大以至不能表示时，某些运算就会溢出(overflow)。例如，32位的`int`类型不能容纳`200*300*400*500`的结果

浮点运算有不同的数学属性，当其溢出时，会产生特殊的值`+∞`，由于表示的精度有限，浮点运算是不可结合的，例如，在很多机器上，C表达式(3.14+1e20)-1e20求得的值会是0.0，而3.14+(1e20-1e20)求得的值会是3.14

这种情况在整数运算中不会出现，因为整数表示的范围虽然小，但是是精确的；而浮点数虽然可以编码较大的数值范围，但是这种表示只是近似的

为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统和编译器组合的可移植性，了解可以表示的数字值的范围、位级表示、算术运算的属性是非常重要的

### 信息存储

大多数计算机使用8位的块，或者字节(byte)，作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为*虚拟内存(virtual address space)*。这个虚拟地址空间只是一个展现给机器级程序的概念性映像，实际的实现结合了动态随机访问存储器(DRAM)、闪存、磁盘存储器、特殊硬件以及操作系统，为程序提供一个看上去统一的字节数组。

#### 十六进制表示法

一个字节由8位组成。在二进制标识法中，它的值域是00000000 ~ 11111111，看成十进制整数，就是0 ~ 255。两种符号标识发对于描述位模式都不是很方便。二进制标识发太冗长，十进制表示法与位模式的互相转换很麻烦。替代的方法是使用十六进制(hexadecimal)数来表示位模式。十六进制(简写为"hex")使用数字0 ~ 9以及字符A ~ F来表示16个可能的值。用十六进制来书写，一个字节的值域为00 ~ FF

![](/assets/img/CSAPP-21.JPG)

在C语言中，以Ox或OX开头的数字常量常被认为是十六进制的值。字符A ~ F既可以是大写，也可以是小写。例如，我们可以将数字FA1D37B(16进制)写作OxFA1D37B，或者Oxfa1d37b，甚至是大小写混合，在这本书里，是用C表示法来表示十六进制的

编写机器级程序的一个常见任务就是在位模式的十进制、二进制和十六进制表示之间人工转换。二进制和十六进制之间的转换比较简单直接，因为可以一次执行一个十六进制数字的转换。

比如，一个数字0x173A4C，可以通过展开每个十六进制数字，将其转换成二进制：

`1:0001` `7:0111` `3:0011` `A:1010` `4:0100` `C:1100`

这样就得到了二进制表示：`000101110011101001001100`

反过来，如果给定了一个二进制数字`1111001010110110110011`，可以通过首先把它分为每4位一组来转换为十六进制。不过要注意，如果总位数不是4的倍数，最左边的一组可以少于4位，前面用0补足

`11:3` `1100:C` `1010:A` `1101:D` `1011:B` `0011:3`

#### 字数据大小

每台计算机都有一个字长(word size)，指明指针数据的标称大小(nominal size)。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于以字长为w位的机器而言，虚拟地址的范围为0 ~ 2的w次方-1，程序最多访问2的w次方个字节

最近这些年，出现了大规模从32位字长机器到64位字长机器的迁移。32位字长限制虚拟地址空间位4千兆字节(写作4GB)，而扩展到64位字长使得虚拟地址空间为16EB，大约是1.84*10的19次方字节

大多数64位机器也可以运行为32位机器编译的程序，这是一种向后兼容，将程序称为"32位程序"或"64位程序"时，区别在于该程序是如何编译的，而不是其运行的机器类型。

![](/assets/img/CSAPP-22.JPG)

为了避免由于依赖"典型"大小和不同编译器设置带来的奇怪行为，ISO C99引入了一类数据类型，其数据大小是固定的，不随编译器和机器设置而变化。其中就有`int32_t`和`int64_t`，分别位4个字节和8个字节，使用确定大小的整数类型是程序员准确控制数据表示的最佳途径

大部分数据类型都编码为有符号数值，除非有前缀关键字`unsigned`或对确定大小的数据类型使用了特定的无符号声明。对关键字的顺序以及包括还是省略可选关键字来说，C语言允许存在多种形式，比如，这里所有的声明都是一个意思：

- `unsigned long`
- `unsigned long int`
- `long unsigned`
- `long unsigned int`

上面的图中还展示了指针(图中使用了一个被声明为类型"char * "的变量)，使用程序的全字长

> 在C中，任何数据类型`T`，声明`T *p;`，表明`p`是一个指针变量，指向一个类型为`T`的对象。例如`char *p`就将一个指针声明为指向一个`char`类型的变量

程序员应该力图使他们的程序在不同的机器和编译器上可移植，可移植的一个方面就是使程序对不同数据类型的确切大小不敏感。许多程序编写都假设为上面图中32位程序的字节分配。随着64位机器的日益普及，在将这些程序移植到新机器上时，比如有许多程序员假设一个声明为`int`类型的程序对象能被用来存储一个指针。这在大多数32位的机器上能正常功能，但是在一台64位的机器上却会导致问题。

#### 寻址和字节顺序

对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。在几乎所有机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。例如，假设一个类型为`int`的变量`x`的地址为0x100，也就是说，地址表达式`&x`的值为0x100。那么，如果x为32位表示，x的4个字节将被存储在内存的0x100、0x101、0x102和0x103位置

排列表示一个对象的字节有两个通用的规则，小端法(little endian)和大端法(big endian)，分别表示在内存中按照最低有效字节到最高有效字节顺寻存储和从最高有效字节到最低有效字节的顺序存储。

假设变量`x`的类型位`int`，位于地址0x100处，它的十六进制值为0x01234567。地址范围0x100 ~ 0x103的字节顺序依赖于机器的类型：

![](/assets/img/CSAPP-23.JPG)

在字0x01234567中，高位字节的十六进制位0x01，而低位字节值为0x67

大多数Intel兼容机都只用小端模式，另一方面，IBM和Oracle的大多数机器则是按照大端模式操作。许多比较新的微处理器使用的是双端法(bi-endian)，也就是说可以把它们配置成作为打断或者小段的机器运行。实际情况中，一旦选择了特定操作系统，字节顺序就固定了。选择何种字节顺序没有技术上的理由，只要选择了一种规则并且一直遵循，对于哪种字节排序的选择都是任意的。

对于大多数应用程序员来说，其机器所使用的字节顺序是完全不可见的。不过有时候，字节顺序会成为问题。在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接受程序发现里面的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示

当阅读小端法机器生成的机器级程序表示时，经常会将字节按照相反的顺序显示。因为按照小端法，最低有效位在右边，所以会从右边开始排，这值得注意

还有一种情况是当编写规避正常的类型系统的程序时。在C语言中，可以通过强制类型转换(cast)或联合(union)来允许一种数据引用一个对象，而这种数据类型与创建这个对象时定义的数据类型不同。虽然很多应用编程都强烈不推荐这种编码技巧，但是它们对系统及编程来说是非常有用的

看这段代码：

```c
# include <stdio.h>
typedef unsigned char *byte_pointer;

void show_bytes(byte_pointer start, size_t len){
    size_t i;
    for (i = 0; i < len; i++)
        printf(" %.2x", start[i]);
    printf("\n");
}

void show_int(int x){
    show_bytes((byte_pointer) &x, sizeof(int));
}

void show_float(float x){
    show_bytes((byte_pointer) &x, sizeof(float));
}

void show_pointer(void *x){
    show_bytes((byte_pointer) &x, sizeof(void *))
}
```

这段代码使用强制类型转换来访问和打印不同程序对象的字节表示。我们用`typedef`将数据类型`byte_pointer`定义为一个指向类型为`unsigned char`的对象的指针。这样一个字节指针引用一个字节序列，每个字节都被认为是一个非负整数。上面的代码中`show_bytes`函数传入了一个字节序列的地址(传入了字节指针和字节数)，字节数的数据类型是`size_t`，表示数据结构大小的首选数据类型。`show_bytes`打印出每个以十六进制表示的字节。C格式化指令`%.2x`表明整数必须用至少两个数字的十六进制格式输出

`show_bytes`之后的三个函数分别用`show_bytes`来输出了类型为`int`、`float`和`void *`的C程序对象的字节表示。在调用`show_bytes`时，传入的是被强制转换为`unsigned char *`类型的指向它们参数`x`的指针`&x`，这种强制类型转换告诉编译器，程序应该把这个指针看成指向一个字节序列，而不是指向一个原始数据类型的对象。然后，这个指针会被看成是对象使用的最低字节地址。注意这里使用了`sizeof`运算符来确定对象使用的字节数。一般来说，`sizeof(T)`返回存储一个类型为`T`的对象锁需要的字节数。使用`sizeof`而不是固定值，也有利于之后程序的移植。

![](/assets/img/CSAPP-24.JPG)

上图是在不同的机器/操作系统调用前面代码的输出结果，可以看到，除了数值类型因为小端法与大端法造成的字节输出顺序的不同之外，指针值也是完全不同的，不同的机器/操作系统使用不同的存储分配规则。另一个值得注意的特性是上面除了Linux 64使用8字节地址之外，其他操作系统都是使用4字节地址。

> C语言小技巧：`typeof`声明提供了一种给数据类型命名的方式。这能极大改善代码的可读性，因为深度嵌套的类型声明很难读懂；·`printf`(以及`fprintf`和`sprintf`)提供了一种打印信息的方式，在第一个参数格式串(format string)里，每个以`%`开始的字符序列都表示如何格式化下一个参数，比较典型的有`%d`是输出一个十进制整数，而`%c`是输出一个字符，其编码由参数给出，指定确定大小数据类型的格式，如`int32_t`，要更复杂一些，之后会提到
>
> 在函数`show_bytes`中，我们看到指针和数组之间紧密的关系，之后会详细介绍这一点。在代码中，我们还可以看到取地址运算符`&`，这分别创建了指向三种不同类型的`x`的指针，在这里三个指针的类型分别为`int*`、`float*`和`void **`(数据类型void *是一种特殊类型的指针，没有相关联的类型信息)
>
> 强制类型转换运算符可以将一种数据类型转换为另一种，比如`(byte_pointer)&x`表明无论指针`&x`以前是什么类型，它现在就是一个指向数据类型为`unsigned char`的指针。这里给出的强制类型转换不会改变真实的指针，它们只是告诉编译器以新的数据类型来看代被指向的数据。